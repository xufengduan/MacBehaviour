#' Run an Experiment Based on the Configuration
#'
#' Executes the experiment and saves the results to an Excel file.
#'
#' @param gptConfig A list containing the configuration for the language model, including the system prompt,
#' model specifications, and token settings.
#' @param savePath The file path where the experiment results will be saved in Excel format.
#' Defaults to './output.xlsx' in the current working directory.
#'
#' @return This function does not return a value but saves the experiment results to the specified Excel file.
#' Upon completion, "Done." will be printed to the console.
#'
#' @export
#'
#' @examples
#' \dontrun{
#'
#' runExperiment(Experiment_config,"./output.xlsx")
#'
#' #The first argument Experiment_config is generated by preCheck() function.
#'
#' Experiment_config <- preCheck(data)
#' }
runExperiment<- function (gptConfig,savePath="./output.xlsx"){
  if(Sys.getenv("model")=="openai"){
    run_openai(gptConfig,savePath)
  }
  else if(Sys.getenv("model")=="llama"){
    run_llama(gptConfig,savePath)
  }
}




#' Internal Execution of the Experiment Scenarios
#'
#' @description
#' This internal function manages the execution of the experiment scenarios based on the gptConfig settings.
#' It iteratively processes the data for each run and trial, interacts with the GPT model,
#' and appends the results in the designated Excel file. It is utilized within the 'runExperiment' function.
#' @import openxlsx
#' @param gptConfig A list containing the configuration for the GPT model, including the system prompt,
#' model specifications, token settings, and experiment mode.
#' @param savePath The file path where the experiment results will be saved in Excel format.
#'
#' @return This function does not return a value but executes the experiment scenarios and
#' compiles the results in an Excel file. It prints "Done." to the console upon completion.
#'
#' @noRd
run_openai<- function(gptConfig,savePath){
  data <- as.data.frame(gptConfig[1])
  systemPrompt <- gptConfig$systemPrompt
  model <- gptConfig$model
  max_tokens <- gptConfig$max_tokens
  temperature <- gptConfig$temperature
  top_p <- gptConfig$top_p
  n <- gptConfig$n

  total_iterations <- nrow(data) * n

  progress_bar <- txtProgressBar(min = 0, max = total_iterations, style = 3)

  current_progress <- 0

  data$Response <- NA

  data$N <- NA
  data$Trial <- NA
  data$Message <- NA

  wb <- createWorkbook()
  addWorksheet(wb, "Sheet1")
  writeData(wb, sheet = 1, x = t(colnames(data)), startRow = 1, startCol = 1,colNames = FALSE)
  row_num <- 2

  for (s in unique(data$Session)) {
    s_data <- data[data$Session == s, ]
    # Run loop
    for (r in unique(data$Run)) {
      r_data <- s_data[s_data$Run == r, ]
      messages=list()
      messages=addMessage(messages,"system", systemPrompt)
      print(r)
      # Trial loop
      for (i in seq_len(nrow(r_data))) {
        messages=addMessage(messages,"user",r_data$Prompt[i])
        t_data <- r_data[i,]

        repeat {
          result <- tryCatch({
            content_list = openai_chat(messages, system_prompt, model, temperature, max_tokens, frequency_penalty = 0.0, presence_penalty = 0.0, top_p, n)
            TRUE
            #print(content_list)
          }, error = function(e) {
            print(paste("wariming:", e))
            FALSE
          })

          if (!isTRUE(result)) {
            Sys.sleep(6)
          } else {
            break
          }
        }

        #print(messages)
        if (length(content_list) == 1) {
          content_str <- content_list
        } else {
          content_str <- paste(content_list, collapse = "\n")
        }
        # N responses loop
        for(nr in seq_along(content_list)){{
          t_data$Response <- content_list[nr]
          t_data$N <- nr
          #print(t_data$Response)
          if (n==1){
            messages=addMessage(messages,"assistant",content_list[nr])
            #print(messages)
          }
          cMessage <- paste(messages, collapse = " ")
          #print(cMessage)
          new_row <- c(t_data$Run, t_data$Item, t_data$Condition,t_data$Prompt, t_data$Session,t_data$Response, t_data$N,i,cMessage)
          writeData(wb, sheet = 1, x = t(new_row), startRow = row_num, startCol = 1,colNames = FALSE)
          row_num <- row_num + 1
          current_progress <- current_progress + 1
          setTxtProgressBar(progress_bar, current_progress)

        }
          saveWorkbook(wb, savePath, overwrite = TRUE)
        }
      }
    }
  }

  close(progress_bar)
  print("Done.")
}







#' Internal Execution of the Experiment Scenarios
#'
#' @description
#' This internal function manages the execution of the experiment scenarios based on the gptConfig settings.
#' It iteratively processes the data for each run and trial, interacts with the llama model,
#' and appends the results in the designated Excel file. It is utilized within the 'runExperiment' function.
#' @import openxlsx
#' @param gptConfig A list containing the configuration for the llama model, including the system prompt,
#' model specifications, token settings, and experiment mode.
#' @param savePath The file path where the experiment results will be saved in Excel format.
#'
#' @return This function does not return a value but executes the experiment scenarios and
#' compiles the results in an Excel file. It prints "Done." to the console upon completion.
#'
#' @noRd
run_llama<- function(gptConfig,savePath){
  data <- as.data.frame(gptConfig[1])
  systemPrompt <- gptConfig$systemPrompt
  # model <- gptConfig$model
  max_tokens <- gptConfig$max_tokens
  temperature <- gptConfig$temperature
  top_p <- gptConfig$top_p
  n <- 1

  total_iterations <- nrow(data) * n

  progress_bar <- txtProgressBar(min = 0, max = total_iterations, style = 3)

  current_progress <- 0

  data$Response <- NA

  data$N <- NA
  data$Trial <- NA
  data$Message <- NA

  wb <- createWorkbook()
  addWorksheet(wb, "Sheet1")
  writeData(wb, sheet = 1, x = t(colnames(data)), startRow = 1, startCol = 1,colNames = FALSE)
  row_num <- 2

  for (s in unique(data$Session)) {
    s_data <- data[data$Session == s, ]

    # Run loop
    for (r in unique(data$Run)) {
      r_data <- s_data[s_data$Run == r, ]

   ######################################################
      messages=""
      messages=addMessage(messages,"system", systemPrompt)


   ######################################################

      print(r)
      # Trial loop
      for (i in seq_len(nrow(r_data))) {
        messages=addMessage(messages,"user",r_data$Prompt[i])
        t_data <- r_data[i,]

        repeat {
          result <- tryCatch({
            content_list = llama_chat(messages, temperature, max_tokens,top_p)
            TRUE
            #print(content_list)
          }, error = function(e) {
            print(paste("wariming:", e))
            FALSE
          })

          if (!isTRUE(result)) {
            Sys.sleep(5)
          } else {
            break
          }
        }

          t_data$Response <- content_list
          t_data$N <- 1
          #print(t_data$Response)

          messages=addMessage(messages,"assistant",content_list)


          cMessage <- paste(messages, collapse = " ")
          #print(cMessage)
          new_row <- c(t_data$Run, t_data$Item, t_data$Condition,t_data$Prompt, t_data$Session,t_data$Response, t_data$N,i,cMessage)
          writeData(wb, sheet = 1, x = t(new_row), startRow = row_num, startCol = 1,colNames = FALSE)
          row_num <- row_num + 1
          current_progress <- current_progress + 1
          setTxtProgressBar(progress_bar, current_progress)

          saveWorkbook(wb, savePath, overwrite = TRUE)


      }
    }
  }

  close(progress_bar)
  print("Done.")
}




